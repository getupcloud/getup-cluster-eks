apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ingress-nginx
  namespace: flux-system
spec:
  chart:
    spec:
      chart: ingress-nginx
      sourceRef:
        kind: HelmRepository
        name: ingress-nginx
      version: "4.12.x"
  dependsOn:
  - name: monitoring
  install:
    createNamespace: true
    disableWait: true
    remediation:
      # Ingress can not be retried in order to avoid the loadbalancer service to be deleted between attempts
      retries: 0
  upgrade:
    disableWait: true
    remediation:
      # Ingress can not be retried in order to avoid the loadbalancer service to be deleted between attmpts
      retries: 0
  interval: 10m
  releaseName: ingress-nginx
  storageNamespace: ingress-nginx
  targetNamespace: ingress-nginx
  values:
    controller:
      #kind: Deployment
      replicaCount: 2

      # PodDisruptionBudget
      # Define either 'minAvailable' or 'maxUnavailable', never both.
      minAvailable: 1
      #maxUnavailable: 1

      resources:
        limits:
          cpu: 300m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 256Mi

      allowSnippetAnnotations: false
      enableAnnotationValidations: true

      admissionWebhooks:
        # enable after install in order to avoid ingress deadlock
        enabled: false

      #priorityClassName: high-priority

      #dnsPolicy: ClusterFirstWithHostNet

      extraArgs:
        enable-ssl-passthrough: "false"
        #default-ssl-certificate: "ingress-nginx/default-ssl-certificate" ## "<namespace>/<secret_name>"

      config:
        #use-proxy-protocol: "true"

        # Use ewma load-balancing for high-load envs. It avoids concentrating reqs into a small set of app pods.
        # https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#load-balance
        #load-balance: ewma
        #
        #whitelist-source-range: 10.10.0.0/16,172.168.0.1
        #real-ip-header: proxy_protocol
        #set-real-ip-from: X.X.X.X

      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 30
        targetCPUUtilizationPercentage: 90
        targetMemoryUtilizationPercentage: 90

      keda:
        enabled: false
        minReplicas: 2
        maxReplicas: 30
        triggers:
        # https://keda.sh/docs/2.7/scalers/cpu/
        - type: cpu
          metricType: Utilization
          metadata:
            value: "90" # percentage of requests
        # https://keda.sh/docs/2.7/scalers/memory/
        - type: memory
          metricType: Utilization
          metadata:
            value: "90" # percentage of requests
        #- type: prometheus
        #  metadata:
        #    serverAddress: http://<prometheus-host>:9090
        #    metricName: http_requests_total
        #    threshold: '100'
        #    query: sum(rate(http_requests_total{deployment="my-deployment"}[2m]))

      metrics:
        enabled: true
        serviceMonitor:
          enabled: true

    defaultBackend:
      enabled: true

      resources:
        limits:
          cpu: 50m
          memory: 64Mi
        requests:
          cpu: 20m
          memory: 32Mi

